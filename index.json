[{
    "title": "Temporal difference learning for 2048 game",
    "date": "",
    "description": "",
    "body": "  MathJax.Hub.Config({ tex2jax: { skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'], inlineMath: [['$$','$$']] \u0026\u0026 [['$','$']] } });   Temporal difference (TD) learning TD($\\lambda$) mechanism TD(0) is one of TD learning method which considers only the next state, yet TD(1) is the other kind of TD learning which take the accumulated reward of the following states in the account. TD(1) is the well-known Monte-Carlo method. The difference between them is the target in evaluation function:\n$$V(s) \\gets V(s) + \\alpha(\\text{target} - V(s))$$\nFurthermore, TD($\\lambda$) is the generalized version contains both characteristic of TD(0) and TD(1), and is presented in the following example.\nHere is one game composed only three actions:\n$$s_0 - (a_0, r_0) - s_0\u0026rsquo; \\to s_1 - (a_1, r_1) - s_1\u0026rsquo; \\to s_2$$\nThe target($s_0$) of TD(0) and TD(1) is $r_0 + V(s_1)$ and $r_0 + r_1 + r_2$ respectively. For TD($\\lambda$), the target is\n$$\\text{target}(s_0) = (1-\\lambda) (r_1 + V(s_1)) + (\\lambda \\times (1-\\lambda))(r_0 + r_1 + V(s_2)) + (\\lambda \\times \\lambda) (r_0+r_1+r_2)$$\n$$= r_0 + (1-\\lambda)V(s_1) + \\lambda \\times \\text{target}(s_1)$$\nAfter-state The after-state version uses the state after action to evaluate the value function.\n$$s_0 - (a_0, r_0) - s_0\u0026rsquo; \\to s_1 - (a_1, r_1) - s_1\u0026rsquo; \\to s_2$$\n$$V(s_0\u0026rsquo;) \\gets V(s_0\u0026rsquo;) + \\alpha(r_0 + V(s_1\u0026rsquo;) - V(s_0\u0026rsquo;))$$\nDecide the action based on the largest target.\nBefore-State $$s_0 - (a_0, r_0) - s_0\u0026rsquo; \\to s_1 - (a_1, r_1) - s_1\u0026rsquo; \\to s_2$$\n$$V(s_0) \\gets V(s_0) + \\alpha(r_0 + V(s_1) - V(s_0))$$\nThe (before-)state version uses the state before action to evaluate the value function.\nDecide the action based on the largest target.\nN-tuple network The goal of the n-tuple network is to use features to learn instead of the whole board. Each feature has 8 isomorphisms because of the rotation and reflection.\nIn my model, I train the model with 6 features that are shown below. The features are encoded as a 1-d array with length = $8 \\times 16^6$ which is represented as $x(S)$. (All zeros, except 8 ones.) The value function is approximated by the linear combination of $x(S)$ and weight $\\theta$. The elements of the vector represent the scores of each tuple and are updated through the equation:\n$$\\theta \\gets \\theta + \\alpha \\Delta V\\cdot x(S)$$\nPractice There are 5 functions assigned in the sample code. I revised 2 of them, “select_best_move” and “update_episode” and remain others the same with the demo code.\nIn “select_best_move” function, the key point is that the random tile pop-up with the probability needs to be considered in each move. Inspired by this concept, I add a for loop and an if statement to achieve.\nIn the loop, each grid will be check whether it is empty or not. In the empty grid, the 2-tile and 4-tile will be added and calculate theirs value (using “estimate” function), respectively. The values are summarised using weighted average with the weights 0.9 and 0.1. In the last, the value accumulated by the loop needs to divide by the number of the loop.\nfor (int i = 0; i \u0026lt; 16; i++) { if (after.at(i) == 0) { after.set(i, 1); value_ += 0.9 * estimate(after); after.set(i, 2); value_ += 0.1 * estimate(after); after.set(i, 0); zero_count ++; } } if (zero_count) value_ /= zero_count; Second, the value updating through $V(s_t) \\gets V(s_t) + \\alpha(r_t + V(s_{t+1}) - V(s_t))$ is implemented in the “update_episode” function.\nCompared to the demo code, 2 places are modified. One is that no initial expression in for statement since $V(s_{t+1})$ is adopted in updating $V(s_t)$. Using the example\nto explain the steps in for loop:\nfloat exact = 0; for ( ; path.size(); path.pop_back()) { state\u0026amp; move = path.back(); exact += move.reward(); float error = exact - estimate(move.before_state()); exact = update(move.before_state(), alpha * error); } $$s_0 - (a_0, r_0) - s_0\u0026rsquo; \\to s_1 - (a_1, r_1) - s_1\u0026rsquo; \\to s_2$$\n Select the final state $(s_2, s_2, x, -1)$. Calculate target = $r_2 + V(s_{3})$ by **exact** = $(-1) + 0$. Calculate $r_2 + V(s_{3}) - V(s_2)$ by **error** = exact - $V(s_2)$. Update $V(s_2)$ by exact = $V(s_2) + \\alpha (\\text{error})$ Select the state $(s_1, s_1\u0026rsquo;, r_1, a_1)$. Calculate target = $r_1 + V(s_{2})$ by **exact** = $r_1$ + exact Calculate $r_1 + V(s_{2}) - V(s_1)$ by **error** = exact - $V(s_1)$ Update $V(s_1)$ by $V(s_1)+\\alpha(\\text{error})$ Repeat steps 5 to 8. (Replace $s_1$ by $s_0$ and $s_2$ by $s_1$).  ",
    "ref": "/blog/temporal-difference-learning-for-2048-game/"
  },{
    "title": "Frequentist Statistics vs Bayesian Statistics",
    "date": "",
    "description": "",
    "body": "Knowledge is accumulated based on numbers and text. Each number represents the outcome of the observed event. Extract the information among numbers and estimated the randomness behind events are methods to gather knowledge. Based on probability, which describes randomness, Statistics is a collection of approaches that provides summaries and inferences. According to different utilizations on probability, two main schools are developed: Frequentist Statistics and Bayesian Statistics.\nBefore knowing the approaches deepen, we can start from an example in which we can apply Statistics. A scientific question is whether the average grades of senior high school students in Taiwan increasing by the year. The target is all Taiwan\u0026rsquo;s students; however, we can only obtain a small part of the record among them. As a result, we compute the average that represents the mean of all Taiwan\u0026rsquo;s students. The mean of all Taiwan’s students is the parameter that Statisticians are interested in this example. The way statisticians regard the parameter varies from the Frequentist Statistics and the Bayesian Statistics.\nThe most fundamental difference is inference, which includes the estimation of the parameter and its interval. Frequentist statisticians consider the parameter as a fixed number, while Bayesian statisticians believe the parameter is a random variable and from a distribution. Although the estimation of the parameter is the main goal in Statistics, the error of the estimation is also as important as the estimation. In Frequentist Statistics, Confidence Interval is proposed to measure the estimation error which uses the residuals and the size of the data (e.g. the number of the students in the above example). Whereas Bayesian statisticians create the Confidence Band that is from the corresponded distribution of the estimated parameter.\nDespite the two schools are developed from the contrast concepts, the same results can be obtained sometimes. Bayesian Statistics result is affected by prior information specified. However, if no prior information could be used, the uniform distribution provides an informative prior distribution. Adopting uniform distribution leads to the same result as in Frequentist Statistics. For example, ridge regression is a well-known case.\nBayesian Statisticians and Frequentist Statisticians have not gotten along well with each other for a long time. The two schools are different roads, but they both concerned similar questions.\n",
    "ref": "/blog/frequentist-statistics-vs-bayesian-statistics/"
  },{
    "title": "A revised chart for cfd-trading.com",
    "date": "",
    "description": "",
    "body": "According to the article \u0026ldquo;top performers over the past 24 hours\u0026rdquo; in website World Markets Snapshot, there are 2 key points mentioned. In the first paragraph, the author summarizes the numbers in the category by averaging. Then, the individual stock performance followed. However, it is hard to tell the key points in the current version chart that is shown above. The 2 key points are:\n Which category performs the best/worst? Which individual stock performs the best/worst?  I design a bar chart to emphasize the 2 points. Here are my ideas:\n Separate the bar charts by the categories of stock, and Fill red and green colors representing increasing and decreasing respectively.  In this chart, it is easy to recognize which category performance better by the sum of the number of red bars and specify the best stock performance by finding the longest red bar.\n",
    "ref": "/blog/visualization-for-cfdtrading/"
  },{
    "title": "About Model Fan",
    "date": "",
    "description": "Created by Tina, a Statistics PhD student focusing on spatial statistics and machine learning.",
    "body": "",
    "ref": "/about/"
  },{
    "title": "",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/contact/"
  }]
